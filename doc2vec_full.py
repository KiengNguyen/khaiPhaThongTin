import gensim
from gensim.models.doc2vec import Doc2Vec, TaggedDocument
import os
from underthesea import word_tokenize
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity


def read_text_file(file_path):
    """ƒê·ªçc d·ªØ li·ªáu t·ª´ file vƒÉn b·∫£n"""
    if os.path.isfile(file_path):
        with open(file_path, "r", encoding="utf-8") as file:
            return file.read()
    else:
        print(f"File {file_path} kh√¥ng t·ªìn t·∫°i.")
        return None


def preprocess_text(text):
    """Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n: t√°ch t·ª´ v√† chuy·ªÉn th√†nh ch·ªØ th∆∞·ªùng"""
    return word_tokenize(text, format="text").lower()


def read_files_from_folder(folder_path):
    """ƒê·ªçc t·∫•t c·∫£ c√°c file .txt trong th∆∞ m·ª•c"""
    documents = []
    for filename in os.listdir(folder_path):
        file_path = os.path.join(folder_path, filename)
        if os.path.isfile(file_path) and filename.endswith(".txt"):  # Ch·ªâ ƒë·ªçc file .txt
            text = read_text_file(file_path)
            if text:
                documents.append(preprocess_text(text))
    return documents


def train_doc2vec_for_each_topic(root_folder):
    """Hu·∫•n luy·ªán m√¥ h√¨nh Doc2Vec cho t·ª´ng ch·ªß ƒë·ªÅ trong th∆∞ m·ª•c g·ªëc v√† hi·ªÉn th·ªã s·ªë l∆∞·ª£ng file hu·∫•n luy·ªán"""
    total_files = 0  # Bi·∫øn ƒë·∫øm t·ªïng s·ªë file

    for topic in os.listdir(root_folder):
        topic_path = os.path.join(root_folder, topic)
        if os.path.isdir(topic_path):  # Ki·ªÉm tra n·∫øu l√† th∆∞ m·ª•c con (ch·ªß ƒë·ªÅ)
            print(f"üîπ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh cho ch·ªß ƒë·ªÅ: {topic}")
            texts = read_files_from_folder(topic_path)

            num_files = len(texts)  # ƒê·∫øm s·ªë file trong ch·ªß ƒë·ªÅ n√†y
            total_files += num_files  # C·ªông d·ªìn v√†o t·ªïng s·ªë file

            if num_files == 0:
                print(f"‚ö†Ô∏è B·ªè qua ch·ªß ƒë·ªÅ {topic} v√¨ kh√¥ng c√≥ d·ªØ li·ªáu.")
                continue

            print(f"üìÇ S·ªë file hu·∫•n luy·ªán trong ch·ªß ƒë·ªÅ '{topic}': {num_files}")

            documents = [TaggedDocument(words=text.split(), tags=[f"{topic}_doc_{i}"]) for i, text in enumerate(texts)]
            model = Doc2Vec(documents, vector_size=500, window=5, min_count=1, workers=4, epochs=20)

            model_path = f"doc2vec_{topic}.model"
            model.save(model_path)
            print(f"‚úÖ M√¥ h√¨nh cho ch·ªß ƒë·ªÅ '{topic}' ƒë√£ ƒë∆∞·ª£c l∆∞u: {model_path}\n")

    print(f"üî• T·ªïng s·ªë file ƒë√£ hu·∫•n luy·ªán tr√™n t·∫•t c·∫£ c√°c ch·ªß ƒë·ªÅ: {total_files}")


def get_vector_from_file(file_path, model_path):
    """L·∫•y vector t·ª´ m·ªôt file c·ª• th·ªÉ b·∫±ng m√¥ h√¨nh Doc2Vec"""
    text = read_text_file(file_path)
    if text:
        processed_text = preprocess_text(text)
        model = Doc2Vec.load(model_path)
        vector = model.infer_vector(processed_text.split())
        print(f"Vector bi·ªÉu di·ªÖn file {file_path}:", vector)
        return vector
    return None
def compare_vectors(vector1, vector2):
    """So s√°nh hai vector b·∫±ng Cosine Similarity v√† Euclidean Distance"""
    vector1 = np.array(vector1).reshape(1, -1)
    vector2 = np.array(vector2).reshape(1, -1)

    cosine_sim = cosine_similarity(vector1, vector2)[0][0]
    euclidean_dist = np.linalg.norm(vector1 - vector2)
    print("------K·∫øt qu·∫£ so s√°nh-------")
    print(f"ƒê·ªô t∆∞∆°ng ƒë·ªìng Cosine: {cosine_sim:.4f}")
    print(f"Kho·∫£ng c√°ch Euclidean: {euclidean_dist:.4f}")

    return cosine_sim, euclidean_dist

if __name__ == "__main__":
    data_root_dir = "data/vnexpress/"  # Th∆∞ m·ª•c g·ªëc ch·ª©a c√°c ch·ªß ƒë·ªÅ
    train_doc2vec_for_each_topic(data_root_dir)

    # ƒê·ªçc m·ªôt file c·ª• th·ªÉ v√† l·∫•y vector
    file_path_1 = "data/vnexpress_data/the-thao/7_sai_l·∫ßm_runner_hay_m·∫Øc_ph·∫£i_khi_ch·∫•n_th∆∞∆°ng.txt"
    vector1 = get_vector_from_file(file_path_1,"doc2vec_the-thao.model")
    file_path_2 = "data/vnexpress_data/suc-khoe/4_m√≥n_ƒÉn_u·ªëng_kh√¥ng_t·ªët_cho_tinh_binh.txt"
    vector2 = get_vector_from_file(file_path_2,"doc2vec_suc-khoe.model")
    file_path_3 = "data/vnexpress_data/suc-khoe/7_hi·ªÉu_l·∫ßm_v·ªÅ_b·ªánh_s·ªüi_·ªü_ng∆∞·ªùi_l·ªõn.txt"
    vector3 = get_vector_from_file(file_path_3,"doc2vec_suc-khoe.model")

    # So s√°nh hai vector
    compare_vectors(vector1, vector2)
    compare_vectors(vector3, vector3)
