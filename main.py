import os
import numpy as np
import pickle
from word2vec_tn2 import model_w2v, document_vector
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier, NearestCentroid
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import MinMaxScaler
from gensim.models import Word2Vec

import pickle

# T·∫£i m√¥ h√¨nh Word2Vec ƒë√£ hu·∫•n luy·ªán
try:
    model_w2v = Word2Vec.load("word2vec.model")
except Exception as e:
    print(f"‚ö†Ô∏è L·ªói khi t·∫£i m√¥ h√¨nh Word2Vec: {e}")
    model_w2v = None
    
# H√†m ƒë·ªçc c√°c vƒÉn b·∫£n v√† nh√£n t·ª´ th∆∞ m·ª•c vnexpress_data
def read_labeled_documents(folder_path):
    """ƒê·ªçc to√†n b·ªô c√°c file .txt v√† tr·∫£ v·ªÅ danh s√°ch vƒÉn b·∫£n v√† nh√£n"""
    documents = []
    labels = []
    for label in os.listdir(folder_path):
        label_folder = os.path.join(folder_path, label)
        
        if os.path.isdir(label_folder):
            for filename in os.listdir(label_folder):
                if filename.endswith(".txt"):
                    file_path = os.path.join(label_folder, filename)
                    with open(file_path, "r", encoding="utf-8") as f:
                        doc_content = f.read()
                        documents.append(doc_content)
                        labels.append(label)  # Nh√£n l√† t√™n th∆∞ m·ª•c con
    return documents, labels

# ƒê·ªçc d·ªØ li·ªáu v√† nh√£n th·ª±c t·∫ø
documents, labels = read_labeled_documents("vnexpress_tap_kiem_thu")
print(f"üìÇ ƒê√£ ƒë·ªçc {len(documents)} vƒÉn b·∫£n v·ªõi {len(labels)} nh√£n.")

# Chuy·ªÉn c√°c vƒÉn b·∫£n th√†nh vector
X = np.array([document_vector(model_w2v, doc) for doc in documents])

# Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p ki·ªÉm tra
X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)

# Chu·∫©n h√≥a d·ªØ li·ªáu
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Hu·∫•n luy·ªán m√¥ h√¨nh KNN
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train_scaled, y_train)
with open("knn_model.pkl", "wb") as f:
    pickle.dump(knn, f)

# Hu·∫•n luy·ªán m√¥ h√¨nh Na√Øve Bayes
nb = MultinomialNB()
nb.fit(X_train_scaled, y_train)
with open("nb_model.pkl", "wb") as f:
    pickle.dump(nb, f)

# Hu·∫•n luy·ªán m√¥ h√¨nh Rocchio (NearestCentroid) n·∫øu ch∆∞a c√≥ t·ªáp m√¥ h√¨nh
if not os.path.exists("rocchio_model.pkl"):
    rocchio = NearestCentroid()
    rocchio.fit(X_train_scaled, y_train)
    with open("rocchio_model.pkl", "wb") as f:
        pickle.dump(rocchio, f)
    print("üéØ ƒê√£ l∆∞u m√¥ h√¨nh Rocchio.")

# ƒê·ªçc m√¥ h√¨nh KNN, Na√Øve Bayes v√† Rocchio ƒë√£ l∆∞u
with open("knn_model.pkl", "rb") as f:
    knn = pickle.load(f)
with open("nb_model.pkl", "rb") as f:
    nb = pickle.load(f)
with open("rocchio_model.pkl", "rb") as f:
    rocchio = pickle.load(f)

# D·ª± ƒëo√°n nh√£n cho t·∫≠p ki·ªÉm tra
y_pred_knn = knn.predict(X_test_scaled)
y_pred_nb = nb.predict(X_test_scaled)

# C√†i ƒë·∫∑t thu·∫≠t to√°n Rocchio (NearestCentroid)
rocchio = NearestCentroid()
rocchio.fit(X_train_scaled, y_train)  # D√πng t·∫≠p hu·∫•n luy·ªán ƒë·ªÉ hu·∫•n luy·ªán Rocchio
y_pred_rocchio = rocchio.predict(X_test_scaled)

# ƒê√°nh gi√° k·∫øt qu·∫£ cho KNN
knn_precision = precision_score(y_test, y_pred_knn, average='weighted', zero_division=1)
knn_recall = recall_score(y_test, y_pred_knn, average='weighted', zero_division=1)
knn_f1 = f1_score(y_test, y_pred_knn, average='weighted', zero_division=1)
knn_accuracy = accuracy_score(y_test, y_pred_knn)

# ƒê√°nh gi√° k·∫øt qu·∫£ cho Na√Øve Bayes
nb_precision = precision_score(y_test, y_pred_nb, average='weighted', zero_division=1)
nb_recall = recall_score(y_test, y_pred_nb, average='weighted', zero_division=1)
nb_f1 = f1_score(y_test, y_pred_nb, average='weighted', zero_division=1)
nb_accuracy = accuracy_score(y_test, y_pred_nb)

# ƒê√°nh gi√° k·∫øt qu·∫£ cho Rocchio (Nearest Centroid)
rocchio_precision = precision_score(y_test, y_pred_rocchio, average='weighted', zero_division=1)
rocchio_recall = recall_score(y_test, y_pred_rocchio, average='weighted', zero_division=1)
rocchio_f1 = f1_score(y_test, y_pred_rocchio, average='weighted', zero_division=1)
rocchio_accuracy = accuracy_score(y_test, y_pred_rocchio)

# In k·∫øt qu·∫£ ƒë√°nh gi√°
print(f"üéØ KNN Accuracy: {knn_accuracy:.4f}, Precision: {knn_precision:.4f}, Recall: {knn_recall:.4f}, F1-Score: {knn_f1:.4f}")
print(f"üéØ Na√Øve Bayes Accuracy: {nb_accuracy:.4f}, Precision: {nb_precision:.4f}, Recall: {nb_recall:.4f}, F1-Score: {nb_f1:.4f}")
print(f"üéØ Rocchio Accuracy: {rocchio_accuracy:.4f}, Precision: {rocchio_precision:.4f}, Recall: {rocchio_recall:.4f}, F1-Score: {rocchio_f1:.4f}")


# L∆∞u nh√£n ph√¢n l·ªõp v√†o file
with open("labels_predicted_knn.txt", "w", encoding="utf-8") as f:
    for label in y_pred_knn:
        f.write(label + "\n")

with open("labels_predicted_nb.txt", "w", encoding="utf-8") as f:
    for label in y_pred_nb:
        f.write(label + "\n")

with open("labels_predicted_rocchio.txt", "w", encoding="utf-8") as f:
    for label in y_pred_rocchio:
        f.write(label + "\n")

print("\n‚úÖ Nh√£n ph√¢n l·ªõp ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o file.")